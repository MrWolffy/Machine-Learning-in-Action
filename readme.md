# 《机器学习实战》

## 预测分类数据

### Ch2 K-近邻算法

K-近邻算法找出距离样本点最近的k个个体，通过投票法则进行分类

应用于：任何类型的数据，但要事先定义距离

缺点：计算量大

### Ch3 决策树

决策树可以按照一定的顺序，将数据每次按照一个特征划分到某一类中，递归完成分类

应用于：数值型数据和分类数据

缺点：可能过度匹配

### Ch4 朴素贝叶斯

朴素贝叶斯利用贝叶斯公式计算样本点分类为每个类别的条件概率，并选出最大的条件概率作为分类结果

应用于：数值型数据和分类数据

缺点：假定严格，需要各特征不相关

### Ch5 Logistic回归

略

### Ch6 支持向量机

支持向量机可以解决二分类数据的划分问题

应用于：数值型数据和分类数据

缺点：结果不稳定，受到参数和核函数选择的影响

### Ch7 利用AdaBoost元算法提高分类性能

AdaBoost通过多次使用简单分类器构造出一个更复杂的分类器，以提高分类准确度

应用于：数值型数据和分类数据

缺点：对分类器个数敏感

## 预测数值型数据

### Ch8 回归

略

### Ch9 树回归

树回归先将样本分类到某一个回归模型中，再用该回归模型预测

应用于：数值型数据和分类数据

缺点：对参数敏感，结果不易理解

## 无监督学习

### Ch10 利用K-均值聚类算法对未标注数据分组

K-均值算法产生K个中心点，如果样本距离一个中心点比其他中心点都近，则该样本属于该中心点那一类

应用于：数值型数据

缺点：可能收敛到局部最小值，速度慢

### Ch11 使用Apriori算法进行关联分析

Apriori算法可以发现数据集中关联度高的特征，并且可以发现特征之间的“因果关系”

应用于：数值型数据和分类数据

缺点：计算量大

### Ch12 使用FP-growth算法来高效发现频繁项集

FP-growth算法可以更高效地发现数据集中关联度高的特征

## 其他工具

### Ch13 利用PCA来简化数据

### Ch14 利用SVD简化数据